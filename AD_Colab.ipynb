{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AD: Colab",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfysXS74pr-o",
        "colab_type": "code",
        "outputId": "69b61bb8-a70a-4536-e540-fcc75cfaf0d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjHSaW1rjzoa",
        "colab_type": "code",
        "outputId": "313ce90a-f0be-4cc0-dcf2-1bc3842a9ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 12 00:46:11 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiQ1uD1-j27p",
        "colab_type": "code",
        "outputId": "6e2b0378-b4b4-4caa-df05-e6cda137a8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86DVG7ADga7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/ericzhao28/ActiveDialogue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM026rL03XYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2cca5b6-0cc3-475a-8eab-8883b187c77e"
      },
      "source": [
        "%cd ActiveDialogue"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ActiveDialogue\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRNCnWJRwMTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!bash setup.sh\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sG6kFZXoaJ5",
        "colab_type": "code",
        "outputId": "f8074d7a-a1f5-4753-f8fa-f29147019aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!git reset HEAD --hard\n",
        "!git pull"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HEAD is now at 9ba4538 Fix seed argpasre\n",
            "Updating 9ba4538..e5c0360\n",
            "Fast-forward\n",
            " ActiveDialogue/main/seed.py    | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " ActiveDialogue/main/vanilla.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 2 insertions(+), 2 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jJEdgNrrXv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shared = \"\"\"\n",
        "        --device 0\n",
        "        --seed 2\n",
        "        --nick colab\n",
        "        --dexp '/content/gdrive/My Drive/Colab Notebooks/exp'\n",
        "        \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfvCVzXloaXH",
        "colab_type": "code",
        "outputId": "8c634d95-edb4-489a-ffeb-7f31a93b8f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from ActiveDialogue.main.seed import main\n",
        "\n",
        "main(\"--lr 0.003 --force_seed --seed_epochs 100 --model glad\" + shared)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: ----------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary:\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     url: https://www.comet.ml/ericzhao28/activedialogue/9541e85dd5ff4eefb99427517f10e5a2\n",
            "COMET INFO:   Metrics [count] (min, max):\n",
            "COMET INFO:     Final seed Example label proportion: (0.0, 0.0)\n",
            "COMET INFO:     Final seed Exhausted label budget  : (0.0, 0.0)\n",
            "COMET INFO:     Final seed Exhausted labels        : (0.0, 0.0)\n",
            "COMET INFO:     Final seed Stream progress         : (0.0, 0.0)\n",
            "COMET INFO:     Final seed joint_goal              : (0.0024096385542168677, 0.0024096385542168677)\n",
            "COMET INFO:     Final seed turn_inform             : (0.5337349397590362, 0.5337349397590362)\n",
            "COMET INFO:     Final seed turn_request            : (0.7108433734939759, 0.7108433734939759)\n",
            "COMET INFO:     sys.cpu.percent.01 [3]             : (1.6, 6.7)\n",
            "COMET INFO:     sys.cpu.percent.02 [3]             : (1.7, 19.3)\n",
            "COMET INFO:     sys.cpu.percent.avg [3]            : (1.65, 13.0)\n",
            "COMET INFO:     sys.gpu.0.free_memory [3]          : (13562150912.0, 17071734784.0)\n",
            "COMET INFO:     sys.gpu.0.gpu_utilization [3]      : (0.0, 0.0)\n",
            "COMET INFO:     sys.gpu.0.total_memory             : (17071734784.0, 17071734784.0)\n",
            "COMET INFO:     sys.gpu.0.used_memory [3]          : (0.0, 3509583872.0)\n",
            "COMET INFO:     sys.ram.total [3]                  : (13653561344.0, 13653561344.0)\n",
            "COMET INFO:     sys.ram.used [3]                   : (693379072.0, 2755985408.0)\n",
            "COMET INFO: ----------------------------\n",
            "COMET INFO: old comet version (3.1.1) detected. current: 3.1.4 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/ericzhao28/activedialogue/4e9ce54c8ae64cdaaae06a76e2bdc5d6\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading Woz dataset.\n",
            "Loading Woz dataset.\n",
            "Woz: loading split train\n",
            "Woz: loading split train\n",
            "Loaded 2536 turns.\n",
            "Loaded 2536 turns.\n",
            "Loaded 600 dialogues.\n",
            "Loaded 600 dialogues.\n",
            "94 classes\n",
            "94 classes\n",
            "Woz: loading split dev\n",
            "Woz: loading split dev\n",
            "Loaded 830 turns.\n",
            "Loaded 830 turns.\n",
            "Loaded 200 dialogues.\n",
            "Loaded 200 dialogues.\n",
            "94 classes\n",
            "94 classes\n",
            "Woz: loading split test\n",
            "Woz: loading split test\n",
            "Loaded 1646 turns.\n",
            "Loaded 1646 turns.\n",
            "Loaded 400 dialogues.\n",
            "Loaded 400 dialogues.\n",
            "94 classes\n",
            "94 classes\n",
            "dataset sizes: {'train': 600, 'dev': 200, 'test': 400}\n",
            "dataset sizes: {'train': 600, 'dev': 200, 'test': 400}\n",
            "First 10 dataset stream pointers: [2123 1142 2180 1498 1557 1940 1601 2145 1795 1230]\n",
            "First 10 dataset stream pointers: [2123 1142 2180 1498 1557 1940 1601 2145 1795 1230]\n",
            "Seed size: 1000\n",
            "Seed size: 1000\n",
            "Pool size: 1536\n",
            "Pool size: 1536\n",
            "loading model from /content/gdrive/My Drive/Colab Notebooks/exp/colab/seed2.t7\n",
            "loading model from /content/gdrive/My Drive/Colab Notebooks/exp/colab/seed2.t7\n",
            "Loaded seed.\n",
            "Loaded seed.\n",
            "Training seed regardless.\n",
            "Training seed regardless.\n",
            "Running dev evaluation\n",
            "Running dev evaluation\n",
            "Running dev evaluation\n",
            "Running dev evaluation\n",
            "Epoch metrics: {'Stream progress': 0.0, 'Exhausted label budget': 0.0, 'Exhausted labels': 0, 'Example label proportion': 0.0, 'turn_inform': 0.5337349397590362, 'turn_request': 0.7108433734939759, 'joint_goal': 0.0024096385542168677}\n",
            "Epoch metrics: {'Stream progress': 0.0, 'Exhausted label budget': 0.0, 'Exhausted labels': 0, 'Example label proportion': 0.0, 'turn_inform': 0.5337349397590362, 'turn_request': 0.7108433734939759, 'joint_goal': 0.0024096385542168677}\n",
            "Starting fit epoch 1.\n",
            "Starting fit epoch 1.\n",
            "Running dev evaluation\n",
            "Running dev evaluation\n",
            "Epoch metrics: {'Stream progress': 0.0, 'Exhausted label budget': 0.0, 'Exhausted labels': 0, 'Example label proportion': 0.0, 'turn_inform': 0.5325301204819277, 'turn_request': 0.7096385542168675, 'joint_goal': 0.0}\n",
            "Epoch metrics: {'Stream progress': 0.0, 'Exhausted label budget': 0.0, 'Exhausted labels': 0, 'Example label proportion': 0.0, 'turn_inform': 0.5325301204819277, 'turn_request': 0.7096385542168675, 'joint_goal': 0.0}\n",
            "Starting fit epoch 2.\n",
            "Starting fit epoch 2.\n",
            "Running dev evaluation\n",
            "Running dev evaluation\n",
            "Epoch metrics: {'Stream progress': 0.0, 'Exhausted label budget': 0.0, 'Exhausted labels': 0, 'Example label proportion': 0.0, 'turn_inform': 0.5493975903614458, 'turn_request': 0.7108433734939759, 'joint_goal': 0.0}\n",
            "Epoch metrics: {'Stream progress': 0.0, 'Exhausted label budget': 0.0, 'Exhausted labels': 0, 'Example label proportion': 0.0, 'turn_inform': 0.5493975903614458, 'turn_request': 0.7108433734939759, 'joint_goal': 0.0}\n",
            "Starting fit epoch 3.\n",
            "Starting fit epoch 3.\n",
            "Running dev evaluation\n",
            "Running dev evaluation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hpdXipnokNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ActiveDialogue.main.vanilla import main"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n29hiG_VoknG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main(\"--strategy bald --init_threshold 0.4 --model glad\" + shared)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mOd1upDrjZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main(\"--strategy entropy --init_threshold 10.0 --model glad\" + shared)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0xLdLvUrl9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main(\"--strategy aggressive --model glad\" + shared)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XiK0x8urmH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main(\"--strategy passive --model glad\" + shared)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q9_pPjvhsqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 vanilla_runner.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEI5hUrijUuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}